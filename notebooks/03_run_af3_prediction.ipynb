{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Run AlphaFold 3 Prediction for Antibody-Antigen Complexes\n",
    "\n",
    "This notebook runs AlphaFold 3 predictions using the same bind-mount layout as `00_test_af3_setup.ipynb`.\n",
    "\n",
    "**Requirements:**\n",
    "- Run on a GPU node: `srun --partition=dhvi-gpu --gres=gpu:1 --mem=10G -c 6 --pty bash`\n",
    "- Load CUDA if needed: `module load CUDA/11.4`\n",
    "\n",
    "**Bind mounts (matches working HPC script):**\n",
    "- Host input dir → `/root/af_input`\n",
    "- Host output dir → `/root/af_output`\n",
    "- Model parameters → `/root/models`\n",
    "- Databases → `/root/public_databases`\n",
    "- AF3 program dir → `/root/AF3`\n",
    "- Temp dir → `/tmp` (prevents cleanup errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF3 Configuration\n",
      "============================================================\n",
      "APPTAINER_TMPDIR:   /scratch/hsb26/tmp\n",
      "APPTAINER_CACHEDIR: /cwork/hsb26/cache\n",
      "TMPDIR:             /scratch/hsb26/af3_tmp\n",
      "AF3_HOME:           /opt/apps/community/alphafold3\n",
      "SIF_IMAGE:          /opt/apps/community/alphafold3/AF3_v3.0.1.sif\n",
      "DATABASES_DIR:      /opt/apps/community/alphafold3/AF3_databases\n",
      "MODEL_PARAMS_DIR:   /opt/apps/community/alphafold3/AF3_models\n",
      "AF3_PROGRAMS_DIR:   /opt/apps/community/alphafold3/AF3_Programs/alphafold3\n",
      "AF3_INPUT_DIR:      /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_inputs\n",
      "AF3_OUTPUT_DIR:     /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_outputs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# =============================================================================\n",
    "# Configuration - matches run_AF3_wk24_glycan.job and 00_test_af3_setup.ipynb\n",
    "# =============================================================================\n",
    "\n",
    "user = os.environ.get(\"USER\", \"unknown\")\n",
    "\n",
    "# Runtime / Apptainer directories\n",
    "os.environ.setdefault(\"APPTAINER_TMPDIR\", f\"/scratch/{user}/tmp\")\n",
    "os.environ.setdefault(\"APPTAINER_CACHEDIR\", f\"/cwork/{user}/cache\")\n",
    "\n",
    "# IMPORTANT: Set TMPDIR for Python's tempfile module (used by Jackhmmer)\n",
    "# This prevents cleanup errors when container/host have permission conflicts\n",
    "TMPDIR = Path(f\"/scratch/{user}/af3_tmp\")\n",
    "TMPDIR.mkdir(parents=True, exist_ok=True)\n",
    "os.environ[\"TMPDIR\"] = str(TMPDIR)\n",
    "os.environ[\"TEMP\"] = str(TMPDIR)\n",
    "os.environ[\"TMP\"] = str(TMPDIR)\n",
    "\n",
    "# Ensure scratch/cache dirs exist\n",
    "Path(os.environ[\"APPTAINER_TMPDIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.environ[\"APPTAINER_CACHEDIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# AF3 paths (same as run_AF3_wk24_glycan.job)\n",
    "AF3_HOME = Path(\"/opt/apps/community/alphafold3\")\n",
    "DATABASES_DIR = AF3_HOME / \"AF3_databases\"\n",
    "MODEL_PARAMETERS_DIR = AF3_HOME / \"AF3_models\"\n",
    "AF3_PROGRAMS_DIR = AF3_HOME / \"AF3_Programs\" / \"alphafold3\"\n",
    "\n",
    "# SIF image: find the first available\n",
    "SIF_CANDIDATES = [\n",
    "    AF3_HOME / \"AF_v3.0.1.sif\",\n",
    "    AF3_HOME / \"AF3_v3.0.1.sif\",\n",
    "    AF3_HOME / \"AF3_111125.sif\",\n",
    "]\n",
    "SIF_IMAGE = None\n",
    "for candidate in SIF_CANDIDATES:\n",
    "    if candidate.exists():\n",
    "        SIF_IMAGE = candidate\n",
    "        break\n",
    "\n",
    "# Input/output directories (project-relative paths)\n",
    "PROJECT_ROOT = Path(f\"/cwork/{user}/ab_seq_bind_analysis\")\n",
    "AF3_INPUT_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"af3_inputs\"\n",
    "AF3_OUTPUT_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"af3_outputs\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "AF3_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"AF3 Configuration\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"APPTAINER_TMPDIR:   {os.environ.get('APPTAINER_TMPDIR')}\")\n",
    "print(f\"APPTAINER_CACHEDIR: {os.environ.get('APPTAINER_CACHEDIR')}\")\n",
    "print(f\"TMPDIR:             {os.environ.get('TMPDIR')}\")\n",
    "print(f\"AF3_HOME:           {AF3_HOME}\")\n",
    "print(f\"SIF_IMAGE:          {SIF_IMAGE}\")\n",
    "print(f\"DATABASES_DIR:      {DATABASES_DIR}\")\n",
    "print(f\"MODEL_PARAMS_DIR:   {MODEL_PARAMETERS_DIR}\")\n",
    "print(f\"AF3_PROGRAMS_DIR:   {AF3_PROGRAMS_DIR}\")\n",
    "print(f\"AF3_INPUT_DIR:      {AF3_INPUT_DIR}\")\n",
    "print(f\"AF3_OUTPUT_DIR:     {AF3_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-select",
   "metadata": {},
   "source": [
    "## 1. Select Input Complex\n",
    "\n",
    "Choose which antibody-antigen complex to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "list-inputs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available input complexes:\n",
      "============================================================\n",
      "   0. P10A1_1JPL_WT.json\n",
      "   1. P10A9_1JPL_WT.json\n",
      "   2. P12E11_H3_JHB_94.json\n",
      "   3. P13C1_1JPLm414_C_G1.json\n",
      "   4. P17A1_1JPLm414_T_G3.json\n",
      "   5. P17E9_H3_JHB_94.json\n",
      "   6. P1A8_1JPLm414_C_G1.json\n",
      "   7. P22H12_1JPLm414_T_G3.json\n",
      "   8. P23F10_1JPL_4I.json\n",
      "   9. P24E7_H3_JHB_94.json\n",
      "  10. P25G10_H3_JHB_94.json\n",
      "  11. P27D10_H3_JHB_94.json\n",
      "  12. P28A7_1JPLm414_C_G1.json\n",
      "  13. P28A7_1JPLm414_T_G3.json\n",
      "  14. P30A5_1JPLm414_T_G3.json\n",
      "  15. P31A3_1JPLm414_C_G1.json\n",
      "  16. P32B9_H3_JHB_94.json\n",
      "  17. P32G11_1JPL_WT.json\n",
      "  18. P33F7_HK68.json\n",
      "  19. P34E9_1JPLm414_C_G1.json\n",
      "  20. P35A1_1JPLm414_C_G1.json\n",
      "  21. P35A1_1JPLm414_T_G3.json\n",
      "  22. P35C12_1JPLm414_C_G1.json\n",
      "  23. P36B2_1JPLm414_T_G3.json\n",
      "  24. P36D8_1JPLm414_C_G1.json\n",
      "  25. P36H10_1JPL_WT.json\n",
      "  26. P37G10_HK68.json\n",
      "  27. P38B10_1JPL_4I.json\n",
      "  28. P38B10_HK68.json\n",
      "  29. P38B11_1JPLm414_T_G3.json\n",
      "  30. P38F11_1JPL_4I.json\n",
      "  31. P38F11_HK68.json\n",
      "  32. P39A3_1JPLm414_C_G1.json\n",
      "  33. P39A3_1JPLm414_T_G3.json\n",
      "  34. P40A10_HK68.json\n",
      "  35. P40G1_1JPL_4I.json\n",
      "  36. P40G1_1JPLm414_C_G1.json\n",
      "  37. P40G1_1JPLm414_T_G3.json\n",
      "  38. P40G1_H3_JHB_94.json\n",
      "  39. P40G1_HK68.json\n",
      "  40. P40H7_HK68.json\n",
      "  41. P41A9_1JPL_WT.json\n",
      "  42. P41A9_H3_JHB_94.json\n",
      "  43. P44E10_H3_JHB_94.json\n",
      "  44. P45B7_1JPL_4I.json\n",
      "  45. P45B7_H3_JHB_94.json\n",
      "  46. P45B7_HK68.json\n",
      "  47. P46F1_1JPL_4I.json\n",
      "  48. P46F1_1JPL_WT.json\n",
      "  49. P47A9_1JPL_WT.json\n",
      "  50. P47G10_1JPL_WT.json\n",
      "  51. P47H7_1JPL_4I.json\n",
      "  52. P51E9_1JPL_4I.json\n",
      "  53. P51E9_1JPL_WT.json\n",
      "  54. P55E2_1JPL_4I.json\n",
      "  55. P55E2_HK68.json\n",
      "  56. P5E9_1JPL_WT.json\n",
      "  57. P9D11_1JPLm414_T_G3.json\n",
      "\n",
      "Total: 58 input files\n"
     ]
    }
   ],
   "source": [
    "# List available input JSON files\n",
    "print(\"Available input complexes:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "input_files = sorted(AF3_INPUT_DIR.glob(\"*.json\"))\n",
    "input_files = [f for f in input_files if not f.name.startswith(\".\")]  # skip hidden files\n",
    "\n",
    "for i, f in enumerate(input_files):\n",
    "    print(f\"  {i:2d}. {f.name}\")\n",
    "\n",
    "print(f\"\\nTotal: {len(input_files)} input files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "select-input",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected complex: P10A1_1JPL_WT.json\n",
      "Run name: P10A1_1JPL_WT\n",
      "\n",
      "Complex details:\n",
      "  Name: P10A1_1JPL_WT\n",
      "  Seeds: [1]\n",
      "  Chains:\n",
      "    H: 121 residues\n",
      "    L: 112 residues\n",
      "    A: 166 residues\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SELECT YOUR COMPLEX HERE\n",
    "# =============================================================================\n",
    "# Option 1: Select by index from the list above\n",
    "# INPUT_INDEX = 0\n",
    "# INPUT_JSON = input_files[INPUT_INDEX]\n",
    "\n",
    "# Option 2: Specify by name directly (for first actual complex test)\n",
    "INPUT_JSON = AF3_INPUT_DIR / \"P10A1_1JPL_WT.json\"\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "RUN_NAME = INPUT_JSON.stem\n",
    "\n",
    "print(f\"Selected complex: {INPUT_JSON.name}\")\n",
    "print(f\"Run name: {RUN_NAME}\")\n",
    "\n",
    "# Load and display the input JSON\n",
    "with open(INPUT_JSON, \"r\") as f:\n",
    "    input_data = json.load(f)\n",
    "\n",
    "print(f\"\\nComplex details:\")\n",
    "print(f\"  Name: {input_data.get('name')}\")\n",
    "print(f\"  Seeds: {input_data.get('modelSeeds')}\")\n",
    "print(f\"  Chains:\")\n",
    "for seq in input_data.get(\"sequences\", []):\n",
    "    if \"protein\" in seq:\n",
    "        chain_id = seq[\"protein\"][\"id\"]\n",
    "        chain_seq = seq[\"protein\"][\"sequence\"]\n",
    "        print(f\"    {chain_id}: {len(chain_seq)} residues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-validate",
   "metadata": {},
   "source": [
    "## 2. Validate Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "validate-env",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Check\n",
      "============================================================\n",
      "[+] AF3_HOME: /opt/apps/community/alphafold3 - OK\n",
      "[+] SIF_IMAGE: /opt/apps/community/alphafold3/AF3_v3.0.1.sif - OK\n",
      "[+] DATABASES_DIR: /opt/apps/community/alphafold3/AF3_databases - OK\n",
      "[+] MODEL_PARAMETERS_DIR: /opt/apps/community/alphafold3/AF3_models - OK\n",
      "[+] AF3_PROGRAMS_DIR: /opt/apps/community/alphafold3/AF3_Programs/alphafold3 - OK\n",
      "[+] INPUT_JSON: /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_inputs/P10A1_1JPL_WT.json - OK\n",
      "\n",
      "Singularity/Apptainer Check\n",
      "----------------------------------------\n",
      "[+] singularity found: /usr/bin/singularity\n",
      "\n",
      "GPU Check\n",
      "----------------------------------------\n",
      "[+] GPU available: NVIDIA RTX 5000 Ada Generation\n",
      "\n",
      "============================================================\n",
      "Environment validation complete!\n"
     ]
    }
   ],
   "source": [
    "def check_path(label, path, required=True):\n",
    "    \"\"\"Check if a path exists and print status.\"\"\"\n",
    "    exists = path.exists() if path else False\n",
    "    status = \"OK\" if exists else \"MISSING\"\n",
    "    symbol = \"[+]\" if exists else \"[X]\"\n",
    "    print(f\"{symbol} {label}: {path} - {status}\")\n",
    "    if required and not exists:\n",
    "        raise FileNotFoundError(f\"Required path missing: {label} = {path}\")\n",
    "    return exists\n",
    "\n",
    "print(\"Environment Check\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check critical paths\n",
    "check_path(\"AF3_HOME\", AF3_HOME)\n",
    "check_path(\"SIF_IMAGE\", SIF_IMAGE)\n",
    "check_path(\"DATABASES_DIR\", DATABASES_DIR)\n",
    "check_path(\"MODEL_PARAMETERS_DIR\", MODEL_PARAMETERS_DIR)\n",
    "check_path(\"AF3_PROGRAMS_DIR\", AF3_PROGRAMS_DIR)\n",
    "check_path(\"INPUT_JSON\", INPUT_JSON)\n",
    "\n",
    "# Check for singularity/apptainer\n",
    "print(\"\\nSingularity/Apptainer Check\")\n",
    "print(\"-\" * 40)\n",
    "result = subprocess.run([\"which\", \"singularity\"], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(f\"[+] singularity found: {result.stdout.strip()}\")\n",
    "else:\n",
    "    result = subprocess.run([\"which\", \"apptainer\"], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"[+] apptainer found: {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(\"[X] Neither singularity nor apptainer found!\")\n",
    "\n",
    "# Check GPU access\n",
    "print(\"\\nGPU Check\")\n",
    "print(\"-\" * 40)\n",
    "result = subprocess.run([\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader\"], \n",
    "                       capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(f\"[+] GPU available: {result.stdout.strip()}\")\n",
    "else:\n",
    "    print(\"[X] No GPU detected! Run on a GPU node:\")\n",
    "    print(\"    srun --partition=dhvi-gpu --gres=gpu:1 --mem=10G -c 6 --pty bash\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Environment validation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-build-cmd",
   "metadata": {},
   "source": [
    "## 3. Build and Run AF3 Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "build-command",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF3 Command\n",
      "============================================================\n",
      "singularity exec --nv --bind /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_inputs:/root/af_input --bind /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_outputs:/root/af_output --bind /opt/apps/community/alphafold3/AF3_models:/root/models --bind ...\n",
      "\n",
      "Full command:\n",
      "singularity exec --nv --bind /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_inputs:/root/af_input --bind /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_outputs:/root/af_output --bind /opt/apps/community/alphafold3/AF3_models:/root/models --bind /opt/apps/community/alphafold3/AF3_databases:/root/public_databases --bind /opt/apps/community/alphafold3/AF3_Programs/alphafold3:/root/AF3 --bind /scratch/hsb26/af3_tmp:/tmp /opt/apps/community/alphafold3/AF3_v3.0.1.sif python /root/AF3/run_alphafold.py --json_path=/root/af_input/P10A1_1JPL_WT.json --model_dir=/root/models --db_dir=/root/public_databases --output_dir=/root/af_output\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Execution Control\n",
    "# =============================================================================\n",
    "RUN_DATA_PIPELINE = True   # CPU-only genetic/template search\n",
    "RUN_INFERENCE = True       # GPU-required model inference\n",
    "DRY_RUN = False            # Set True to only print command without executing\n",
    "\n",
    "# =============================================================================\n",
    "# Build command with proper bind mounts (matches 00_test_af3_setup.ipynb)\n",
    "# =============================================================================\n",
    "\n",
    "# Clean any leftover temp files from previous failed runs\n",
    "for old_tmp in TMPDIR.glob(\"tmp*\"):\n",
    "    try:\n",
    "        if old_tmp.is_dir():\n",
    "            shutil.rmtree(old_tmp, ignore_errors=True)\n",
    "        else:\n",
    "            old_tmp.unlink(missing_ok=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Build the singularity command\n",
    "cmd = [\n",
    "    \"singularity\", \"exec\", \"--nv\",\n",
    "    \"--bind\", f\"{AF3_INPUT_DIR}:/root/af_input\",\n",
    "    \"--bind\", f\"{AF3_OUTPUT_DIR}:/root/af_output\",\n",
    "    \"--bind\", f\"{MODEL_PARAMETERS_DIR}:/root/models\",\n",
    "    \"--bind\", f\"{DATABASES_DIR}:/root/public_databases\",\n",
    "    \"--bind\", f\"{AF3_PROGRAMS_DIR}:/root/AF3\",\n",
    "    # Bind temp directory to prevent cleanup errors\n",
    "    \"--bind\", f\"{TMPDIR}:/tmp\",\n",
    "    str(SIF_IMAGE),\n",
    "    \"python\", \"/root/AF3/run_alphafold.py\",\n",
    "    f\"--json_path=/root/af_input/{INPUT_JSON.name}\",\n",
    "    \"--model_dir=/root/models\",\n",
    "    \"--db_dir=/root/public_databases\",\n",
    "    \"--output_dir=/root/af_output\",\n",
    "]\n",
    "\n",
    "# Add optional flags\n",
    "if not RUN_DATA_PIPELINE:\n",
    "    cmd.append(\"--run_data_pipeline=false\")\n",
    "if not RUN_INFERENCE:\n",
    "    cmd.append(\"--run_inference=false\")\n",
    "\n",
    "print(\"AF3 Command\")\n",
    "print(\"=\" * 60)\n",
    "print(\" \".join(cmd[:10]) + \" ...\")\n",
    "print()\n",
    "print(\"Full command:\")\n",
    "print(\" \".join(cmd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "run-prediction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AF3 prediction for: P10A1_1JPL_WT\n",
      "============================================================\n",
      "Started: 2026-02-03T15:46:06.405073\n",
      "\n",
      "This may take 30-60+ minutes for antibody-antigen complexes.\n",
      "\n",
      "Progress:\n",
      "------------------------------------------------------------\n",
      "⠋ [0:03:20] Jackhmmer (2/4)                    \n",
      "I0203 15:49:26.677670 140293194106432 subprocess_utils.py:97] Finished Jackhmmer (bfd-first_non_consensus_sequences.fasta) in 168.875 seconds\n",
      "⠏ [0:13:59] Jackhmmer (4/4)                    \n",
      "I0203 16:00:05.620727 140293210891840 subprocess_utils.py:97] Finished Jackhmmer (uniref90_2022_05.fa) in 807.818 seconds\n",
      "⠏ [0:16:49] Jackhmmer (6/4)                    \n",
      "I0203 16:02:56.288481 140293185713728 subprocess_utils.py:97] Finished Jackhmmer (uniprot_all_2021_04.fa) in 978.485 seconds\n",
      "⠹ [0:21:22] Jackhmmer (8/4)                    \n",
      "I0203 16:07:28.586431 140293202499136 subprocess_utils.py:97] Finished Jackhmmer (mgy_clusters_2022_05.fa) in 1250.783 seconds\n",
      "\n",
      "I0203 16:07:29.078211 140301133235328 subprocess_utils.py:97] Finished Hmmbuild in 0.316 seconds\n",
      "⠙ [0:21:31] Jackhmmer (8/4)                    \n",
      "I0203 16:07:37.778782 140301133235328 subprocess_utils.py:97] Finished Hmmsearch (pdb_seqres_2022_09_28.fasta) in 8.699 seconds\n",
      "⠦ [0:24:16] Jackhmmer (10/4)                    \n",
      "I0203 16:10:22.810952 140293210891840 subprocess_utils.py:97] Finished Jackhmmer (bfd-first_non_consensus_sequences.fasta) in 164.400 seconds\n",
      "⠙ [0:33:31] Jackhmmer (12/4)                    \n",
      "I0203 16:19:37.918403 140293202499136 subprocess_utils.py:97] Finished Jackhmmer (uniref90_2022_05.fa) in 719.511 seconds\n",
      "⠴ [0:36:45] Jackhmmer (14/4)                    \n",
      "I0203 16:22:51.441926 140293194106432 subprocess_utils.py:97] Finished Jackhmmer (uniprot_all_2021_04.fa) in 913.032 seconds\n",
      "⠋ [0:41:50] Jackhmmer (16/4)                    \n",
      "I0203 16:27:57.155852 140293185713728 subprocess_utils.py:97] Finished Jackhmmer (mgy_clusters_2022_05.fa) in 1218.748 seconds\n",
      "\n",
      "I0203 16:27:57.585163 140301133235328 subprocess_utils.py:97] Finished Hmmbuild in 0.259 seconds\n",
      "⠧ [0:41:57] Jackhmmer (16/4)                    \n",
      "I0203 16:28:03.750180 140301133235328 subprocess_utils.py:97] Finished Hmmsearch (pdb_seqres_2022_09_28.fasta) in 6.161 seconds\n",
      "⠙ [0:45:01] Jackhmmer (18/4)                    \n",
      "I0203 16:31:07.738652 140293202499136 subprocess_utils.py:97] Finished Jackhmmer (bfd-first_non_consensus_sequences.fasta) in 183.219 seconds\n",
      "⠙ [0:55:01] Jackhmmer (20/4)                    \n",
      "I0203 16:41:07.448278 140293185713728 subprocess_utils.py:97] Finished Jackhmmer (uniref90_2022_05.fa) in 782.927 seconds\n",
      "⠼ [0:58:34] Jackhmmer (22/4)                    \n",
      "I0203 16:44:41.025793 140293210891840 subprocess_utils.py:97] Finished Jackhmmer (uniprot_all_2021_04.fa) in 996.505 seconds\n",
      "⠹ [1:03:22] Jackhmmer (24/4)                    \n",
      "I0203 16:49:29.281264 140293194106432 subprocess_utils.py:97] Finished Jackhmmer (mgy_clusters_2022_05.fa) in 1284.826 seconds\n",
      "\n",
      "I0203 16:49:29.549261 140301133235328 subprocess_utils.py:97] Finished Hmmbuild in 0.176 seconds\n",
      "⠏ [1:03:29] Jackhmmer (24/4)                    \n",
      "I0203 16:49:36.006557 140301133235328 subprocess_utils.py:97] Finished Hmmsearch (pdb_seqres_2022_09_28.fasta) in 6.454 seconds\n",
      "⠼ [1:05:14] Jackhmmer (24/4)                    \n",
      "Running fold job P10A1_1JPL_WT...\n",
      "\n",
      "Output will be written in /root/af_output/p10a1_1jpl_wt\n",
      "\n",
      "\n",
      "============================================================\n",
      "Total time: 1:05:18\n",
      "[+] AF3 prediction completed successfully!\n",
      "Finished: 2026-02-03T16:51:24.527989\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Run AF3 Prediction\n",
    "# =============================================================================\n",
    "\n",
    "run_info = {\n",
    "    \"timestamp_start\": datetime.now().isoformat(),\n",
    "    \"input_json\": str(INPUT_JSON),\n",
    "    \"run_name\": RUN_NAME,\n",
    "    \"output_dir\": str(AF3_OUTPUT_DIR),\n",
    "    \"run_data_pipeline\": RUN_DATA_PIPELINE,\n",
    "    \"run_inference\": RUN_INFERENCE,\n",
    "    \"cmd\": \" \".join(cmd),\n",
    "}\n",
    "\n",
    "if DRY_RUN:\n",
    "    print(\"DRY RUN - Command not executed.\")\n",
    "    print(\"Set DRY_RUN = False to run the prediction.\")\n",
    "else:\n",
    "    print(f\"Running AF3 prediction for: {RUN_NAME}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Started: {run_info['timestamp_start']}\")\n",
    "    print(\"\\nThis may take 30-60+ minutes for antibody-antigen complexes.\\n\")\n",
    "    \n",
    "    # Progress tracking\n",
    "    start_time = time.time()\n",
    "    stage_markers = {\n",
    "        \"Running data pipeline\": \"MSA Search\",\n",
    "        \"Jackhmmer\": \"Jackhmmer\",\n",
    "        \"Finished Jackhmmer\": \"Jackhmmer done\",\n",
    "        \"Running model inference\": \"Model Inference\", \n",
    "        \"Running structure module\": \"Structure Module\",\n",
    "        \"Writing output\": \"Writing Output\",\n",
    "        \"Running fold job\": \"Starting fold job\",\n",
    "    }\n",
    "    current_stage = \"Initializing\"\n",
    "    jackhmmer_count = 0\n",
    "    jackhmmer_total = 4  # uniref90, bfd, mgy, uniprot\n",
    "    \n",
    "    def format_elapsed(seconds):\n",
    "        return str(timedelta(seconds=int(seconds)))\n",
    "    \n",
    "    def print_progress(stage, elapsed, extra=\"\"):\n",
    "        spinner = [\"⠋\", \"⠙\", \"⠹\", \"⠸\", \"⠼\", \"⠴\", \"⠦\", \"⠧\", \"⠇\", \"⠏\"]\n",
    "        spin_char = spinner[int(elapsed) % len(spinner)]\n",
    "        msg = f\"\\r{spin_char} [{format_elapsed(elapsed)}] {stage}\"\n",
    "        if extra:\n",
    "            msg += f\" {extra}\"\n",
    "        print(msg + \" \" * 20, end=\"\", flush=True)\n",
    "    \n",
    "    # Run with live output and progress\n",
    "    proc = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1,\n",
    "        env={**os.environ, \"TMPDIR\": \"/tmp\", \"TEMP\": \"/tmp\", \"TMP\": \"/tmp\"}\n",
    "    )\n",
    "    \n",
    "    print(\"Progress:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    last_progress_time = time.time()\n",
    "    output_lines = []\n",
    "    \n",
    "    for line in proc.stdout:\n",
    "        elapsed = time.time() - start_time\n",
    "        output_lines.append(line)\n",
    "        \n",
    "        # Update stage based on output\n",
    "        for marker, stage_name in stage_markers.items():\n",
    "            if marker in line:\n",
    "                if \"Finished Jackhmmer\" in line:\n",
    "                    jackhmmer_count += 1\n",
    "                    current_stage = f\"Jackhmmer ({jackhmmer_count}/{jackhmmer_total})\"\n",
    "                else:\n",
    "                    current_stage = stage_name\n",
    "        \n",
    "        # Print progress update every 2 seconds or on stage change\n",
    "        if time.time() - last_progress_time >= 2:\n",
    "            print_progress(current_stage, elapsed)\n",
    "            last_progress_time = time.time()\n",
    "        \n",
    "        # Also print important log lines\n",
    "        if any(x in line for x in [\"[+]\", \"[X]\", \"Error\", \"error\", \"Finished\", \"Running fold job\", \"Output will be written\"]):\n",
    "            print()  # newline before log\n",
    "            print(line.rstrip())\n",
    "    \n",
    "    rc = proc.wait()\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    run_info[\"timestamp_end\"] = datetime.now().isoformat()\n",
    "    run_info[\"return_code\"] = rc\n",
    "    run_info[\"elapsed_seconds\"] = elapsed\n",
    "    run_info[\"output_tail\"] = output_lines[-100:]\n",
    "    \n",
    "    print()  # Final newline\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Total time: {format_elapsed(elapsed)}\")\n",
    "    if rc == 0:\n",
    "        print(\"[+] AF3 prediction completed successfully!\")\n",
    "    else:\n",
    "        print(f\"[X] AF3 prediction failed with code {rc}\")\n",
    "        # Cleanup any remaining temp files\n",
    "        print(\"\\nCleaning up temp files...\")\n",
    "        for tmp_dir in TMPDIR.glob(\"tmp*\"):\n",
    "            try:\n",
    "                shutil.rmtree(tmp_dir, ignore_errors=True)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"Finished: {run_info['timestamp_end']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-outputs",
   "metadata": {},
   "source": [
    "## 4. Inspect Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "check-outputs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking outputs for: P10A1_1JPL_WT\n",
      "Output directory: /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_outputs/P10A1_1JPL_WT\n",
      "============================================================\n",
      "Output directory does not exist yet.\n",
      "Run the prediction first!\n"
     ]
    }
   ],
   "source": [
    "# Check what outputs were generated\n",
    "output_subdir = AF3_OUTPUT_DIR / RUN_NAME\n",
    "\n",
    "print(f\"Checking outputs for: {RUN_NAME}\")\n",
    "print(f\"Output directory: {output_subdir}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if output_subdir.exists():\n",
    "    files = list(output_subdir.rglob(\"*\"))\n",
    "    if files:\n",
    "        print(f\"Found {len(files)} files/directories:\\n\")\n",
    "        for f in sorted(files)[:30]:\n",
    "            rel = f.relative_to(output_subdir)\n",
    "            if f.is_file():\n",
    "                size = f.stat().st_size\n",
    "                print(f\"  {rel} ({size:,} bytes)\")\n",
    "            else:\n",
    "                print(f\"  {rel}/\")\n",
    "        if len(files) > 30:\n",
    "            print(f\"  ... and {len(files) - 30} more\")\n",
    "    else:\n",
    "        print(\"No output files found.\")\n",
    "else:\n",
    "    print(\"Output directory does not exist yet.\")\n",
    "    print(\"Run the prediction first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "save-run-info",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No run info to save (prediction not run yet).\n"
     ]
    }
   ],
   "source": [
    "# Save run info to output directory\n",
    "if 'run_info' in dir() and output_subdir.exists():\n",
    "    run_info_path = output_subdir / \"run_info.json\"\n",
    "    with open(run_info_path, \"w\") as f:\n",
    "        # Don't save output_tail to keep file small\n",
    "        run_info_to_save = {k: v for k, v in run_info.items() if k != 'output_tail'}\n",
    "        json.dump(run_info_to_save, f, indent=2)\n",
    "    print(f\"Saved run info: {run_info_path}\")\n",
    "else:\n",
    "    print(\"No run info to save (prediction not run yet).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "load-confidences",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No confidence summary files found.\n",
      "Run the prediction first!\n"
     ]
    }
   ],
   "source": [
    "# Load and display confidence scores if available\n",
    "summary_files = list(output_subdir.glob(\"**/seed-*_sample-*_summary_confidences.json\")) if output_subdir.exists() else []\n",
    "\n",
    "if summary_files:\n",
    "    print(\"Confidence Summary\")\n",
    "    print(\"=\" * 60)\n",
    "    for sf in sorted(summary_files):\n",
    "        with open(sf) as f:\n",
    "            conf = json.load(f)\n",
    "        print(f\"\\n{sf.parent.name}:\")\n",
    "        for key, value in conf.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"  {key}: {value:.4f}\")\n",
    "            else:\n",
    "                print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"No confidence summary files found.\")\n",
    "    print(\"Run the prediction first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-notes",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "### Running Options\n",
    "\n",
    "**Full prediction (default):**\n",
    "```python\n",
    "RUN_DATA_PIPELINE = True\n",
    "RUN_INFERENCE = True\n",
    "```\n",
    "\n",
    "**CPU-only MSA search (no GPU needed):**\n",
    "```python\n",
    "RUN_DATA_PIPELINE = True\n",
    "RUN_INFERENCE = False\n",
    "```\n",
    "\n",
    "**GPU-only inference (after MSA is done):**\n",
    "```python\n",
    "RUN_DATA_PIPELINE = False\n",
    "RUN_INFERENCE = True\n",
    "```\n",
    "\n",
    "### Temp Directory Cleanup Errors\n",
    "\n",
    "If you see `OSError: [Errno 39] Directory not empty` errors:\n",
    "1. This is often non-fatal - AF3 may have completed successfully\n",
    "2. Check outputs anyway - look for `.cif` files in the output directory\n",
    "3. The notebook binds `/tmp` to prevent most cleanup issues\n",
    "\n",
    "### Expected Runtime\n",
    "\n",
    "- Single protein (~50 residues): ~25 minutes\n",
    "- Antibody-antigen complex (~400 residues total): ~45-90 minutes\n",
    "- Most time is spent in Jackhmmer MSA search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "af3",
   "language": "python",
   "name": "af3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
