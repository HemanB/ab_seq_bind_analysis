{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaFold 3 Structure Prediction\n",
    "\n",
    "This notebook runs AlphaFold 3 structure predictions for antibody-antigen complexes.\n",
    "\n",
    "## Current Run\n",
    "\n",
    "**Input**: `P1A8_1JPLm414_C_G1.json`  \n",
    "**Complex**: Antibody P1A8 with immunogen 1JPLm414_C_G1\n",
    "\n",
    "The JSON file contains all three chains (H, L, Ag) required for complex modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Validation\n",
    "\n",
    "**Validation Checkpoint**: Verify input file exists and paths are correct before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaFold 3 Prediction Run Configuration\n",
      "================================================================================\n",
      "Input JSON: af3_inputs/P1A8_1JPLm414_C_G1.json\n",
      "Sample name: P1A8_1JPLm414_C_G1\n",
      "Output directory: af3_outputs/P1A8_1JPLm414_C_G1\n",
      "Singularity image: /hpc/group/dhvi/WieheLab/MMH/alphafold_v3.0.1/alphafold3.0.1_111125_latest.sif\n",
      "Database directory: /hpc/group/dhvi/WieheLab/AF3_dbs\n",
      "Model directory: /hpc/group/dhvi/WieheLab/AF3_dbs\n",
      "\n",
      "Execution flags:\n",
      "  --run_data_pipeline: True\n",
      "  --run_inference: True\n",
      "\n",
      "Timestamp: 2026-01-28T14:08:28.532737\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "# Host paths (your repo)\n",
    "input_json = \"af3_inputs/P1A8_1JPLm414_C_G1.json\"\n",
    "sample_name = \"P1A8_1JPLm414_C_G1\"\n",
    "output_base_dir = Path(\"af3_outputs\")\n",
    "\n",
    "# AlphaFold 3 installation paths (based on working HPC script)\n",
    "AF3_HOME = Path(\"/opt/apps/community/alphafold3\")\n",
    "DATABASES_DIR = AF3_HOME / \"AF3_databases\"\n",
    "MODEL_PARAMETERS_DIR = AF3_HOME / \"AF3_models\"\n",
    "AF3_PROGRAMS_DIR = AF3_HOME / \"AF3_Programs\" / \"alphafold3\"\n",
    "\n",
    "# Pick the SIF image that exists on this system\n",
    "for candidate in [\n",
    "    AF3_HOME / \"AF3_v3.0.1.sif\",\n",
    "    AF3_HOME / \"AF3_111125.sif\",\n",
    "    AF3_HOME / \"AF_v3.0.1.sif\",\n",
    "]:\n",
    "    if candidate.exists():\n",
    "        SIF_IMAGE = candidate\n",
    "        break\n",
    "else:\n",
    "    SIF_IMAGE = AF3_HOME / \"AF3_v3.0.1.sif\"  # fallback; will fail validation if missing\n",
    "\n",
    "# Container-side mount points (match the working script)\n",
    "CONTAINER_INPUT_DIR = Path(\"/root/af_input\")\n",
    "CONTAINER_OUTPUT_DIR = Path(\"/root/af_output\")\n",
    "CONTAINER_MODEL_DIR = Path(\"/root/models\")\n",
    "CONTAINER_DB_DIR = Path(\"/root/public_databases\")\n",
    "CONTAINER_AF3_DIR = Path(\"/root/AF3\")\n",
    "\n",
    "AF3_SCRIPT_IN_CONTAINER = CONTAINER_AF3_DIR / \"run_alphafold.py\"\n",
    "\n",
    "# Execution control flags (official AF3 flags)\n",
    "# --run_data_pipeline (default true): CPU-only genetic + template search\n",
    "# --run_inference (default true): GPU inference\n",
    "run_data_pipeline = True\n",
    "run_inference = True\n",
    "\n",
    "# Optional: configure Apptainer/Singularity cache locations (helps on HPC)\n",
    "user = os.environ.get(\"USER\", \"unknown\")\n",
    "APPTAINER_TMPDIR = Path(f\"/scratch/{user}/tmp\")\n",
    "APPTAINER_CACHEDIR = Path(f\"/cwork/{user}/cache\")\n",
    "\n",
    "# Track run information\n",
    "run_info = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"input_json\": input_json,\n",
    "    \"sample_name\": sample_name,\n",
    "    \"output_dir\": str((output_base_dir / sample_name).absolute()),\n",
    "    \"af3_home\": str(AF3_HOME),\n",
    "    \"databases_dir\": str(DATABASES_DIR),\n",
    "    \"model_parameters_dir\": str(MODEL_PARAMETERS_DIR),\n",
    "    \"af3_programs_dir\": str(AF3_PROGRAMS_DIR),\n",
    "    \"sif_image\": str(SIF_IMAGE),\n",
    "    \"run_data_pipeline\": run_data_pipeline,\n",
    "    \"run_inference\": run_inference,\n",
    "    \"apptainer_tmpdir\": str(APPTAINER_TMPDIR),\n",
    "    \"apptainer_cachedir\": str(APPTAINER_CACHEDIR),\n",
    "}\n",
    "\n",
    "print(\"AlphaFold 3 Prediction Run Configuration\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Input JSON (host): {input_json}\")\n",
    "print(f\"Sample name: {sample_name}\")\n",
    "print(f\"Output directory (host): {run_info['output_dir']}\")\n",
    "print(\"\\nAlphaFold 3 installation:\")\n",
    "print(f\"  AF3_HOME: {AF3_HOME}\")\n",
    "print(f\"  SIF: {SIF_IMAGE}\")\n",
    "print(f\"  DATABASES_DIR: {DATABASES_DIR}\")\n",
    "print(f\"  MODEL_PARAMETERS_DIR: {MODEL_PARAMETERS_DIR}\")\n",
    "print(f\"  AF3_PROGRAMS_DIR: {AF3_PROGRAMS_DIR}\")\n",
    "print(\"\\nExecution flags:\")\n",
    "print(f\"  --run_data_pipeline: {run_data_pipeline}\")\n",
    "print(f\"  --run_inference: {run_inference}\")\n",
    "print(f\"\\nTimestamp: {run_info['timestamp']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Input file exists: af3_inputs/P1A8_1JPLm414_C_G1.json\n",
      "  File size: 0.75 KB\n",
      "  Last modified: 2026-01-28 00:51:19.587919\n",
      "\n",
      "✓ JSON file is valid\n",
      "  Name: P1A8_1JPLm414_C_G1\n",
      "  Version: 4\n",
      "  Dialect: alphafold3\n",
      "  Number of sequences: 3\n",
      "  Chain IDs: ['H', 'L', 'Ag']\n",
      "  ✓ All required chains present (H, L, Ag)\n",
      "\n",
      "Sequence lengths:\n",
      "  H: 118 amino acids\n",
      "  L: 106 amino acids\n",
      "  Ag: 167 amino acids\n"
     ]
    }
   ],
   "source": [
    "# Validate input file exists\n",
    "input_path = Path(input_json)\n",
    "if not input_path.exists():\n",
    "    raise FileNotFoundError(f\"Input JSON file not found: {input_json}\")\n",
    "\n",
    "print(f\"OK: input file exists: {input_json}\")\n",
    "print(f\"  File size: {input_path.stat().st_size / 1024:.2f} KB\")\n",
    "print(f\"  Last modified: {datetime.fromtimestamp(input_path.stat().st_mtime)}\")\n",
    "\n",
    "# Load and validate JSON structure\n",
    "with open(input_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "print(\"\\nOK: JSON file loaded\")\n",
    "print(f\"  Name: {json_data.get('name', 'N/A')}\")\n",
    "print(f\"  Version: {json_data.get('version', 'N/A')}\")\n",
    "print(f\"  Dialect: {json_data.get('dialect', 'N/A')}\")\n",
    "print(f\"  Number of sequences: {len(json_data.get('sequences', []))}\")\n",
    "\n",
    "# Verify required chains are present (H, L, Ag)\n",
    "sequence_ids = [seq.get('protein', {}).get('id') for seq in json_data.get('sequences', [])]\n",
    "print(f\"  Chain IDs: {sequence_ids}\")\n",
    "\n",
    "required = {\"H\", \"L\", \"Ag\"}\n",
    "found = set(sequence_ids)\n",
    "if found != required:\n",
    "    raise ValueError(f\"Expected chain IDs {sorted(required)}, but found {sequence_ids}\")\n",
    "\n",
    "# Display sequence lengths\n",
    "print(\"\\nSequence lengths:\")\n",
    "for seq in json_data.get('sequences', []):\n",
    "    chain_id = seq['protein']['id']\n",
    "    seq_len = len(seq['protein']['sequence'])\n",
    "    print(f\"  {chain_id}: {seq_len} amino acids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Singularity image exists: /hpc/group/dhvi/WieheLab/MMH/alphafold_v3.0.1/alphafold3.0.1_111125_latest.sif\n",
      "  Image size: 4.92 GB\n",
      "✓ Database directory exists: /hpc/group/dhvi/WieheLab/AF3_dbs\n",
      "\n",
      "✓ Output directory created: af3_outputs/P1A8_1JPLm414_C_G1\n"
     ]
    }
   ],
   "source": [
    "# Optional: set Apptainer env vars if directories exist / can be created\n",
    "try:\n",
    "    APPTAINER_TMPDIR.mkdir(parents=True, exist_ok=True)\n",
    "    os.environ[\"APPTAINER_TMPDIR\"] = str(APPTAINER_TMPDIR)\n",
    "    print(f\"OK: APPTAINER_TMPDIR set to {APPTAINER_TMPDIR}\")\n",
    "except Exception as e:\n",
    "    print(f\"NOTE: Could not set APPTAINER_TMPDIR: {e}\")\n",
    "\n",
    "try:\n",
    "    APPTAINER_CACHEDIR.mkdir(parents=True, exist_ok=True)\n",
    "    os.environ[\"APPTAINER_CACHEDIR\"] = str(APPTAINER_CACHEDIR)\n",
    "    print(f\"OK: APPTAINER_CACHEDIR set to {APPTAINER_CACHEDIR}\")\n",
    "except Exception as e:\n",
    "    print(f\"NOTE: Could not set APPTAINER_CACHEDIR: {e}\")\n",
    "\n",
    "# Check AF3 installation paths\n",
    "for label, p in [\n",
    "    (\"SIF_IMAGE\", SIF_IMAGE),\n",
    "    (\"DATABASES_DIR\", DATABASES_DIR),\n",
    "    (\"MODEL_PARAMETERS_DIR\", MODEL_PARAMETERS_DIR),\n",
    "    (\"AF3_PROGRAMS_DIR\", AF3_PROGRAMS_DIR),\n",
    "]:\n",
    "    if p.exists():\n",
    "        print(f\"OK: {label} exists: {p}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Missing {label}: {p}\")\n",
    "\n",
    "# Create output directory (host)\n",
    "output_dir = output_base_dir / sample_name\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"\\nOK: output directory created: {output_dir}\")\n",
    "\n",
    "# Define host input/output directories for binding\n",
    "host_input_dir = Path(input_json).parent\n",
    "host_output_dir = output_dir\n",
    "\n",
    "print(f\"Host input dir: {host_input_dir.absolute()}\")\n",
    "print(f\"Host output dir: {host_output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation Checkpoint**: Please verify:\n",
    "- Input JSON file exists and is valid\n",
    "- All three chains (H, L, Ag) are present\n",
    "- Sequence lengths are reasonable\n",
    "- AlphaFold 3 SIF + databases + model parameters exist\n",
    "- Output directory created\n",
    "\n",
    "If everything looks correct, proceed to run AlphaFold 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run AlphaFold 3 Prediction\n",
    "\n",
    "**Note**: This may take a significant amount of time depending on system resources. The prediction will run and output will be displayed as it becomes available.\n",
    "\n",
    "**Execution Control**:\n",
    "- `--run_data_pipeline` (default: true): Runs genetic and template search. This is CPU-only and time-consuming. Can be run separately on a machine without GPU.\n",
    "- `--run_inference` (default: true): Runs the inference. This requires a GPU.\n",
    "\n",
    "You can modify these flags in the configuration cell above to control which parts run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlphaFold 3 Command:\n",
      "================================================================================\n",
      "singularity exec --nv \\\n",
      "  -B /cwork:/cwork \\\n",
      "  -B /hpc/group/dhvi/WieheLab/AF3_dbs:/hpc/group/dhvi/WieheLab/AF3_dbs \\\n",
      "  /hpc/group/dhvi/WieheLab/MMH/alphafold_v3.0.1/alphafold3.0.1_111125_latest.sif \\\n",
      "  python /app/alphafold/run_alphafold.py \\\n",
      "    --json_path=/cwork/hsb26/ab_seq_bind_analysis/af3_inputs/P1A8_1JPLm414_C_G1.json --output_dir=/cwork/hsb26/ab_seq_bind_analysis/af3_outputs/P1A8_1JPLm414_C_G1 --db_dir=/hpc/group/dhvi/WieheLab/AF3_dbs --use_templates=false\n",
      "================================================================================\n",
      "\n",
      "Note: This command follows the official AF3 format.\n",
      "Key flags:\n",
      "  --run_data_pipeline: Run genetic and template search (CPU-only)\n",
      "  --run_inference: Run the inference (requires GPU)\n",
      "  Both default to true if not specified\n"
     ]
    }
   ],
   "source": [
    "# Construct the Singularity command (adapted from the working AF3 script)\n",
    "# Bind host input/output/models/databases into standard container locations.\n",
    "\n",
    "# Container expects JSON under /root/af_input\n",
    "json_filename = Path(input_json).name\n",
    "container_json_path = str(CONTAINER_INPUT_DIR / json_filename)\n",
    "\n",
    "# Build flags (official format with equals signs)\n",
    "flags = [\n",
    "    f\"--json_path={container_json_path}\",\n",
    "    f\"--model_dir={CONTAINER_MODEL_DIR}\",\n",
    "    f\"--db_dir={CONTAINER_DB_DIR}\",\n",
    "    f\"--output_dir={CONTAINER_OUTPUT_DIR}\",\n",
    "]\n",
    "\n",
    "# Optional execution control\n",
    "if not run_data_pipeline:\n",
    "    flags.append(\"--run_data_pipeline=false\")\n",
    "if not run_inference:\n",
    "    flags.append(\"--run_inference=false\")\n",
    "\n",
    "command = \" \".join([\n",
    "    \"singularity exec --nv\",\n",
    "    f\"--bind {host_input_dir.absolute()}:{CONTAINER_INPUT_DIR}\",\n",
    "    f\"--bind {host_output_dir.absolute()}:{CONTAINER_OUTPUT_DIR}\",\n",
    "    f\"--bind {MODEL_PARAMETERS_DIR}:{CONTAINER_MODEL_DIR}\",\n",
    "    f\"--bind {DATABASES_DIR}:{CONTAINER_DB_DIR}\",\n",
    "    f\"--bind {AF3_PROGRAMS_DIR}:{CONTAINER_AF3_DIR}\",\n",
    "    str(SIF_IMAGE),\n",
    "    \"python\",\n",
    "    str(AF3_SCRIPT_IN_CONTAINER),\n",
    "    \" \".join(flags),\n",
    "])\n",
    "\n",
    "print(\"AlphaFold 3 Command (Singularity)\")\n",
    "print(\"=\" * 80)\n",
    "print(command)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save command to run info\n",
    "run_info[\"command\"] = command\n",
    "run_info[\"container_json_path\"] = container_json_path\n",
    "run_info[\"flags\"] = flags\n",
    "run_info[\"host_input_dir\"] = str(host_input_dir.absolute())\n",
    "run_info[\"host_output_dir\"] = str(host_output_dir.absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 28 14:33:52 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.86.10              Driver Version: 570.86.10      CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX 5000 Ada Gene...    On  |   00000000:0C:00.0 Off |                  Off |\n",
      "| 30%   18C    P8             17W /  250W |       2MiB /  32760MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting AlphaFold 3 prediction...\n",
      "================================================================================\n",
      "Start time: 2026-01-28T14:33:54.786548\n",
      "\n",
      "FATAL Flags parsing error: Unknown command line flag 'use_templates'. Did you mean: max_template_date ?\n",
      "Pass --helpshort or --helpfull to see help on flags.\n",
      "\n",
      "================================================================================\n",
      "✗ AlphaFold 3 prediction failed with return code: 1\n",
      "Completion time: 2026-01-28T14:34:01.758945\n"
     ]
    }
   ],
   "source": [
    "# Run AlphaFold 3\n",
    "# Note: This will execute the command and stream output\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Starting AlphaFold 3 prediction...\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Start time: {datetime.now().isoformat()}\")\n",
    "print()\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    command,\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    universal_newlines=True,\n",
    "    bufsize=1\n",
    ")\n",
    "\n",
    "output_lines = []\n",
    "for line in process.stdout:\n",
    "    print(line, end='')\n",
    "    output_lines.append(line)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "return_code = process.wait()\n",
    "\n",
    "run_info[\"completion_time\"] = datetime.now().isoformat()\n",
    "run_info[\"return_code\"] = return_code\n",
    "run_info[\"output_lines\"] = output_lines\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "if return_code == 0:\n",
    "    print(\"SUCCESS: AlphaFold 3 prediction completed\")\n",
    "else:\n",
    "    print(f\"FAILURE: AlphaFold 3 prediction failed (return code {return_code})\")\n",
    "print(f\"Completion time: {run_info['completion_time']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check Output Files\n",
    "\n",
    "**Validation Checkpoint**: Verify that output files were generated correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Directory Contents:\n",
      "================================================================================\n",
      "Output directory: af3_outputs/P1A8_1JPLm414_C_G1\n",
      "\n",
      "⚠ No files found in output directory\n"
     ]
    }
   ],
   "source": [
    "# Check output directory contents\n",
    "print(\"Output Directory Contents:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "files = []\n",
    "if output_dir.exists():\n",
    "    files = list(output_dir.glob(\"*\"))\n",
    "    if files:\n",
    "        print(f\"\\nFound {len(files)} files/directories:\")\n",
    "        for f in sorted(files):\n",
    "            if f.is_file():\n",
    "                size = f.stat().st_size\n",
    "                size_str = f\"{size / 1024:.2f} KB\" if size < 1024**2 else f\"{size / (1024**2):.2f} MB\"\n",
    "                print(f\"  - {f.name} ({size_str})\")\n",
    "            else:\n",
    "                print(f\"  - {f.name}/\")\n",
    "\n",
    "        pdb_files = list(output_dir.glob(\"*.pdb\"))\n",
    "        if pdb_files:\n",
    "            print(f\"\\nFound {len(pdb_files)} PDB structure file(s):\")\n",
    "            for pdb in sorted(pdb_files):\n",
    "                print(f\"  - {pdb.name}\")\n",
    "\n",
    "        json_files = list(output_dir.glob(\"*.json\"))\n",
    "        if json_files:\n",
    "            print(f\"\\nFound {len(json_files)} JSON file(s):\")\n",
    "            for jf in sorted(json_files):\n",
    "                print(f\"  - {jf.name}\")\n",
    "    else:\n",
    "        print(\"\\nNo files found in output directory\")\n",
    "else:\n",
    "    print(\"\\nOutput directory does not exist\")\n",
    "\n",
    "run_info[\"output_files\"] = [str(f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Run information saved to: af3_outputs/P1A8_1JPLm414_C_G1/run_info.json\n"
     ]
    }
   ],
   "source": [
    "# Save run information\n",
    "run_info_file = output_dir / \"run_info.json\"\n",
    "with open(run_info_file, 'w') as f:\n",
    "    json.dump(run_info, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Run information saved to: {run_info_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Run Status**: Check the output above to verify:\n",
    "- ✓ Prediction completed (return code 0)\n",
    "- ✓ Output files generated\n",
    "- ✓ PDB structure files present (if successful)\n",
    "\n",
    "**Next Steps**:\n",
    "- Review the generated PDB structure files\n",
    "- Analyze predicted binding interface\n",
    "- Compare with experimental binding data\n",
    "- Run additional predictions if needed\n",
    "\n",
    "**Note**: If you need to run only the data pipeline or only inference separately, modify the `run_data_pipeline` and `run_inference` flags in the configuration cell and re-run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "af3",
   "language": "python",
   "name": "af3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
