{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Test AlphaFold 3 Setup\n",
    "\n",
    "Quick verification that AF3 can run on the cluster.\n",
    "\n",
    "**Requirements:**\n",
    "- Run on a GPU node (e.g., `srun --partition=dhvi-gpu --gres=gpu:1 --pty bash`)\n",
    "- Load CUDA before running: `module load CUDA/11.4`\n",
    "- Singularity/Apptainer available\n",
    "- AF3 databases and models accessible (paths below match `run_AF3_wk24_glycan.job`)\n",
    "\n",
    "**What this tests:**\n",
    "1. Environment validation (paths, image, databases)\n",
    "2. Singularity can load the AF3 container\n",
    "3. GPU is accessible inside container\n",
    "4. (Optional) Run a minimal prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF3 Configuration (run_AF3_wk24_glycan.job)\n",
      "============================================================\n",
      "APPTAINER_TMPDIR:   /scratch/hsb26/tmp\n",
      "APPTAINER_CACHEDIR: /cwork/hsb26/cache\n",
      "TMPDIR:             /scratch/hsb26/af3_tmp\n",
      "AF3_HOME:           /opt/apps/community/alphafold3\n",
      "SIF_IMAGE:          /opt/apps/community/alphafold3/AF3_v3.0.1.sif\n",
      "DATABASES_DIR:      /opt/apps/community/alphafold3/AF3_databases\n",
      "MODEL_PARAMS_DIR:   /opt/apps/community/alphafold3/AF3_models\n",
      "AF3_PROGRAMS_DIR:   /opt/apps/community/alphafold3/AF3_Programs/alphafold3\n",
      "AF3_INPUT_BASE:     /cwork/hsb26/AF3_Input\n",
      "AF3_OUTPUT_BASE:    /cwork/hsb26/AF3_Output\n",
      "TEST_OUTPUT_DIR:    /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_outputs/test_run\n",
      "SLURM:              -p dhvi-gpu --gres=gpu:1 --mem=10G -c 6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# Configuration - matches run_AF3_wk24_glycan.job (WieheLab/MMH)\n",
    "# =============================================================================\n",
    "\n",
    "user = os.environ.get(\"USER\", \"unknown\")\n",
    "\n",
    "# Runtime / Apptainer (set these before running AF3; job script uses these)\n",
    "os.environ.setdefault(\"APPTAINER_TMPDIR\", f\"/scratch/{user}/tmp\")\n",
    "os.environ.setdefault(\"APPTAINER_CACHEDIR\", f\"/cwork/{user}/cache\")\n",
    "# IMPORTANT: Set TMPDIR for Python's tempfile module (used by Jackhmmer)\n",
    "# This prevents cleanup errors when container/host have permission conflicts\n",
    "TMPDIR = Path(f\"/scratch/{user}/af3_tmp\")\n",
    "TMPDIR.mkdir(parents=True, exist_ok=True)\n",
    "os.environ[\"TMPDIR\"] = str(TMPDIR)\n",
    "os.environ[\"TEMP\"] = str(TMPDIR)\n",
    "os.environ[\"TMP\"] = str(TMPDIR)\n",
    "\n",
    "# Ensure scratch/cache dirs exist (job script does: mkdir -p ...)\n",
    "Path(os.environ[\"APPTAINER_TMPDIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.environ[\"APPTAINER_CACHEDIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# AF3 paths (same as run_AF3_wk24_glycan.job)\n",
    "AF3_HOME = Path(\"/opt/apps/community/alphafold3\")\n",
    "DATABASES_DIR = AF3_HOME / \"AF3_databases\"\n",
    "MODEL_PARAMETERS_DIR = AF3_HOME / \"AF3_models\"\n",
    "AF3_PROGRAMS_DIR = AF3_HOME / \"AF3_Programs\" / \"alphafold3\"\n",
    "\n",
    "# SIF image: job uses AF_v3.0.1.sif\n",
    "SIF_CANDIDATES = [\n",
    "    AF3_HOME / \"AF_v3.0.1.sif\",\n",
    "    AF3_HOME / \"AF3_v3.0.1.sif\",\n",
    "    AF3_HOME / \"AF3_111125.sif\",\n",
    "]\n",
    "SIF_IMAGE = None\n",
    "for candidate in SIF_CANDIDATES:\n",
    "    if candidate.exists():\n",
    "        SIF_IMAGE = candidate\n",
    "        break\n",
    "\n",
    "# Input/output base dirs (job convention: /cwork/$USER/AF3_Input, AF3_Output)\n",
    "AF3_INPUT_BASE = Path(f\"/cwork/{user}/AF3_Input\")\n",
    "AF3_OUTPUT_BASE = Path(f\"/cwork/{user}/AF3_Output\")\n",
    "# Test run dirs for this repo\n",
    "TEST_OUTPUT_DIR = Path(f\"/cwork/{user}/ab_seq_bind_analysis/data/processed/af3_outputs/test_run\")\n",
    "\n",
    "# SLURM hints (from job: dhvi-gpu, 10G, 6 CPUs)\n",
    "SLURM_PARTITION = \"dhvi-gpu\"\n",
    "SLURM_GRES = \"gpu:1\"\n",
    "SLURM_MEM = \"10G\"\n",
    "SLURM_CPUS = 6\n",
    "\n",
    "print(\"AF3 Configuration (run_AF3_wk24_glycan.job)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"APPTAINER_TMPDIR:   {os.environ.get('APPTAINER_TMPDIR')}\")\n",
    "print(f\"APPTAINER_CACHEDIR: {os.environ.get('APPTAINER_CACHEDIR')}\")\n",
    "print(f\"TMPDIR:             {os.environ.get('TMPDIR')}\")\n",
    "print(f\"AF3_HOME:           {AF3_HOME}\")\n",
    "print(f\"SIF_IMAGE:          {SIF_IMAGE}\")\n",
    "print(f\"DATABASES_DIR:      {DATABASES_DIR}\")\n",
    "print(f\"MODEL_PARAMS_DIR:   {MODEL_PARAMETERS_DIR}\")\n",
    "print(f\"AF3_PROGRAMS_DIR:   {AF3_PROGRAMS_DIR}\")\n",
    "print(f\"AF3_INPUT_BASE:     {AF3_INPUT_BASE}\")\n",
    "print(f\"AF3_OUTPUT_BASE:    {AF3_OUTPUT_BASE}\")\n",
    "print(f\"TEST_OUTPUT_DIR:    {TEST_OUTPUT_DIR}\")\n",
    "print(f\"SLURM:              -p {SLURM_PARTITION} --gres={SLURM_GRES} --mem={SLURM_MEM} -c {SLURM_CPUS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1. Validate Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "validate-env",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Check\n",
      "============================================================\n",
      "[+] AF3_HOME: /opt/apps/community/alphafold3 - OK\n",
      "[+] SIF_IMAGE: /opt/apps/community/alphafold3/AF3_v3.0.1.sif - OK\n",
      "[+] DATABASES_DIR: /opt/apps/community/alphafold3/AF3_databases - OK\n",
      "[+] MODEL_PARAMETERS_DIR: /opt/apps/community/alphafold3/AF3_models - OK\n",
      "[+] AF3_PROGRAMS_DIR: /opt/apps/community/alphafold3/AF3_Programs/alphafold3 - OK\n",
      "\n",
      "Singularity/Apptainer Check\n",
      "----------------------------------------\n",
      "[+] singularity found: /usr/bin/singularity\n",
      "\n",
      "============================================================\n",
      "Environment validation complete!\n"
     ]
    }
   ],
   "source": [
    "def check_path(label, path, required=True):\n",
    "    \"\"\"Check if a path exists and print status.\"\"\"\n",
    "    exists = path.exists() if path else False\n",
    "    status = \"OK\" if exists else \"MISSING\"\n",
    "    symbol = \"[+]\" if exists else \"[X]\"\n",
    "    print(f\"{symbol} {label}: {path} - {status}\")\n",
    "    if required and not exists:\n",
    "        raise FileNotFoundError(f\"Required path missing: {label} = {path}\")\n",
    "    return exists\n",
    "\n",
    "print(\"Environment Check\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check critical paths\n",
    "check_path(\"AF3_HOME\", AF3_HOME)\n",
    "check_path(\"SIF_IMAGE\", SIF_IMAGE)\n",
    "check_path(\"DATABASES_DIR\", DATABASES_DIR)\n",
    "check_path(\"MODEL_PARAMETERS_DIR\", MODEL_PARAMETERS_DIR)\n",
    "check_path(\"AF3_PROGRAMS_DIR\", AF3_PROGRAMS_DIR)\n",
    "\n",
    "# Check for singularity/apptainer\n",
    "print(\"\\nSingularity/Apptainer Check\")\n",
    "print(\"-\" * 40)\n",
    "result = subprocess.run([\"which\", \"singularity\"], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(f\"[+] singularity found: {result.stdout.strip()}\")\n",
    "else:\n",
    "    result = subprocess.run([\"which\", \"apptainer\"], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"[+] apptainer found: {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(\"[X] Neither singularity nor apptainer found!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Environment validation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. Test Container Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "test-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing container load...\n",
      "============================================================\n",
      "Command: singularity exec /opt/apps/community/alphafold3/AF3_v3.0.1.sif python --version\n",
      "[+] Container loaded successfully\n",
      "    Python version: Python 3.11.11\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing container load...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Simple test: run python --version inside container\n",
    "cmd = [\n",
    "    \"singularity\", \"exec\",\n",
    "    str(SIF_IMAGE),\n",
    "    \"python\", \"--version\"\n",
    "]\n",
    "\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"[+] Container loaded successfully\")\n",
    "    print(f\"    Python version: {result.stdout.strip()}\")\n",
    "else:\n",
    "    print(f\"[X] Container failed to load\")\n",
    "    print(f\"    Error: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. Test GPU Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "test-gpu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GPU access inside container...\n",
      "============================================================\n",
      "Command: singularity exec --nv /opt/apps/community/alphafold3/AF3_v3.0.1.sif nvidia-smi ... nvidia-smi\n",
      "[+] GPU accessible inside container\n",
      "\n",
      "name, memory.total [MiB], driver_version\n",
      "NVIDIA RTX 5000 Ada Generation, 32760 MiB, 570.86.10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing GPU access inside container...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test nvidia-smi inside container\n",
    "cmd = [\n",
    "    \"singularity\", \"exec\", \"--nv\",\n",
    "    str(SIF_IMAGE),\n",
    "    \"nvidia-smi\", \"--query-gpu=name,memory.total,driver_version\", \"--format=csv\"\n",
    "]\n",
    "\n",
    "print(f\"Command: {' '.join(cmd[:5])} ... nvidia-smi\")\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"[+] GPU accessible inside container\")\n",
    "    print(f\"\\n{result.stdout}\")\n",
    "else:\n",
    "    print(f\"[X] GPU not accessible\")\n",
    "    print(f\"    Error: {result.stderr}\")\n",
    "    print(\"\\n    Make sure you're on a GPU node!\")\n",
    "    print(f\"    Try: srun --partition={SLURM_PARTITION} --gres={SLURM_GRES} --pty bash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "test-jax-gpu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing JAX GPU access (used by AF3)...\n",
      "============================================================\n",
      "[+] JAX GPU test passed\n",
      "JAX devices: [CudaDevice(id=0)]\n",
      "GPU available: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing JAX GPU access (used by AF3)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test JAX can see GPU\n",
    "jax_test_script = '''\n",
    "import jax\n",
    "devices = jax.devices()\n",
    "print(f\"JAX devices: {devices}\")\n",
    "print(f\"GPU available: {any('gpu' in str(d).lower() for d in devices)}\")\n",
    "'''\n",
    "\n",
    "cmd = [\n",
    "    \"singularity\", \"exec\", \"--nv\",\n",
    "    str(SIF_IMAGE),\n",
    "    \"python\", \"-c\", jax_test_script\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f\"[+] JAX GPU test passed\")\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    print(f\"[X] JAX GPU test failed\")\n",
    "    print(f\"stdout: {result.stdout}\")\n",
    "    print(f\"stderr: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. Test AF3 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "test-af3-import",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing AF3 module import...\n",
      "============================================================\n",
      "[+] alphafold3.structure imported successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing AF3 module import...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "af3_test_script = '''\n",
    "import sys\n",
    "sys.path.insert(0, \"/root/AF3\")\n",
    "try:\n",
    "    from alphafold3 import structure\n",
    "    print(\"[+] alphafold3.structure imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"[X] Import failed: {e}\")\n",
    "'''\n",
    "\n",
    "cmd = [\n",
    "    \"singularity\", \"exec\", \"--nv\",\n",
    "    \"--bind\", f\"{AF3_PROGRAMS_DIR}:/root/AF3\",\n",
    "    str(SIF_IMAGE),\n",
    "    \"python\", \"-c\", af3_test_script\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(f\"stderr: {result.stderr[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. (Optional) Run Minimal Prediction\n",
    "\n",
    "This runs a very small test prediction to verify the full pipeline works.\n",
    "\n",
    "**Warning:** Even a minimal prediction takes significant time and resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "create-test-input",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created test input: /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_inputs/P10A1_1JPL_WT.json\n",
      "Output will go to: /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_outputs/test_run\n"
     ]
    }
   ],
   "source": [
    "# Create a minimal test input JSON\n",
    "# Using a small antibody fragment for quick testing\n",
    "\n",
    "test_input = {\n",
    "    \"name\": \"test_minimal\",\n",
    "    \"modelSeeds\": [1],\n",
    "    \"dialect\": \"alphafold3\",\n",
    "    \"version\": 3,\n",
    "    \"sequences\": [\n",
    "        {\n",
    "            \"protein\": {\n",
    "                \"id\": \"A\",\n",
    "                # Short test sequence (~50 residues)\n",
    "                \"sequence\": \"MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQDNLSGAEKAVQV\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create test directories\n",
    "TEST_INPUT_DIR = Path(f\"/cwork/{user}/ab_seq_bind_analysis/data/processed/af3_inputs\")\n",
    "TEST_INPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TEST_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "test_json_path = TEST_INPUT_DIR / \"P10A1_1JPL_WT.json\"\n",
    "with open(test_json_path, \"w\") as f:\n",
    "    json.dump(test_input, f, indent=2)\n",
    "\n",
    "print(f\"Created test input: {test_json_path}\")\n",
    "print(f\"Output will go to: {TEST_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "run-test-prediction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running minimal AF3 prediction...\n",
      "============================================================\n",
      "This may take 10-30 minutes even for a small protein.\n",
      "\n",
      "Command:\n",
      "singularity exec --nv --bind /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_inputs:/root/af_input --bind /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_outputs/test_run:/root/af_output --bind /opt/apps/community/alphafold3/AF3_models:/root/models --bind ...\n",
      "\n",
      "Progress:\n",
      "------------------------------------------------------------\n",
      "⠸ [0:00:23] Initializing                    \n",
      "Running fold job test_minimal...\n",
      "\n",
      "Output will be written in /root/af_output/test_minimal\n",
      "⠹ [0:03:42] Jackhmmer (2/4)                    \n",
      "I0202 23:05:48.705152 140504687703616 subprocess_utils.py:97] Finished Jackhmmer (bfd-first_non_consensus_sequences.fasta) in 199.191 seconds\n",
      "⠼ [0:12:54] Jackhmmer (4/4)                    \n",
      "I0202 23:15:00.737345 140538401515072 subprocess_utils.py:97] Finished Jackhmmer (uniref90_2022_05.fa) in 751.225 seconds\n",
      "⠧ [0:18:07] Jackhmmer (6/4)                    \n",
      "I0202 23:20:13.270661 140504679310912 subprocess_utils.py:97] Finished Jackhmmer (uniprot_all_2021_04.fa) in 1063.755 seconds\n",
      "⠦ [0:23:16] Jackhmmer (8/4)                    \n",
      "I0202 23:25:22.876437 140538393122368 subprocess_utils.py:97] Finished Jackhmmer (mgy_clusters_2022_05.fa) in 1373.361 seconds\n",
      "\n",
      "I0202 23:25:23.001944 140546110321792 subprocess_utils.py:97] Finished Hmmbuild in 0.113 seconds\n",
      "⠙ [0:23:21] Jackhmmer (8/4)                    \n",
      "I0202 23:25:26.957304 140546110321792 subprocess_utils.py:97] Finished Hmmsearch (pdb_seqres_2022_09_28.fasta) in 3.954 seconds\n",
      "⠙ [0:24:41] Model Inference                    \n",
      "\n",
      "============================================================\n",
      "Total time: 0:24:45\n",
      "[+] AF3 test prediction completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set to True to actually run the prediction\n",
    "RUN_PREDICTION = True\n",
    "\n",
    "if not RUN_PREDICTION:\n",
    "    print(\"Prediction disabled. Set RUN_PREDICTION = True to run.\")\n",
    "    print(\"\\nThis will run a minimal AF3 prediction to verify the full pipeline.\")\n",
    "else:\n",
    "    import sys\n",
    "    import time\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    print(\"Running minimal AF3 prediction...\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"This may take 10-30 minutes even for a small protein.\\n\")\n",
    "    \n",
    "    # Clean any leftover temp files from previous failed runs\n",
    "    import shutil\n",
    "    for old_tmp in TMPDIR.glob(\"tmp*\"):\n",
    "        try:\n",
    "            if old_tmp.is_dir():\n",
    "                shutil.rmtree(old_tmp, ignore_errors=True)\n",
    "            else:\n",
    "                old_tmp.unlink(missing_ok=True)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    cmd = [\n",
    "        \"singularity\", \"exec\", \"--nv\",\n",
    "        \"--bind\", f\"{TEST_INPUT_DIR}:/root/af_input\",\n",
    "        \"--bind\", f\"{TEST_OUTPUT_DIR}:/root/af_output\",\n",
    "        \"--bind\", f\"{MODEL_PARAMETERS_DIR}:/root/models\",\n",
    "        \"--bind\", f\"{DATABASES_DIR}:/root/public_databases\",\n",
    "        \"--bind\", f\"{AF3_PROGRAMS_DIR}:/root/AF3\",\n",
    "        # Bind temp directory to prevent cleanup errors\n",
    "        \"--bind\", f\"{TMPDIR}:/tmp\",\n",
    "        str(SIF_IMAGE),\n",
    "        \"python\", \"/root/AF3/run_alphafold.py\",\n",
    "        \"--json_path=/root/af_input/P10A1_1JPL_WT.json\",\n",
    "        \"--model_dir=/root/models\",\n",
    "        \"--db_dir=/root/public_databases\",\n",
    "        \"--output_dir=/root/af_output\",\n",
    "    ]\n",
    "    \n",
    "    print(\"Command:\")\n",
    "    print(\" \".join(cmd[:10]) + \" ...\")\n",
    "    print()\n",
    "    \n",
    "    # Progress tracking\n",
    "    start_time = time.time()\n",
    "    stage_markers = {\n",
    "        \"Running data pipeline\": \"MSA Search\",\n",
    "        \"Jackhmmer\": \"Jackhmmer\",\n",
    "        \"Finished Jackhmmer\": \"Jackhmmer done\",\n",
    "        \"Running model inference\": \"Model Inference\", \n",
    "        \"Running structure module\": \"Structure Module\",\n",
    "        \"Writing output\": \"Writing Output\",\n",
    "    }\n",
    "    current_stage = \"Initializing\"\n",
    "    jackhmmer_count = 0\n",
    "    jackhmmer_total = 4  # uniref90, bfd, mgy, uniprot\n",
    "    \n",
    "    def format_elapsed(seconds):\n",
    "        return str(timedelta(seconds=int(seconds)))\n",
    "    \n",
    "    def print_progress(stage, elapsed, extra=\"\"):\n",
    "        bar_width = 40\n",
    "        # Simple spinner\n",
    "        spinner = [\"⠋\", \"⠙\", \"⠹\", \"⠸\", \"⠼\", \"⠴\", \"⠦\", \"⠧\", \"⠇\", \"⠏\"]\n",
    "        spin_char = spinner[int(elapsed) % len(spinner)]\n",
    "        msg = f\"\\r{spin_char} [{format_elapsed(elapsed)}] {stage}\"\n",
    "        if extra:\n",
    "            msg += f\" {extra}\"\n",
    "        print(msg + \" \" * 20, end=\"\", flush=True)\n",
    "    \n",
    "    # Run with live output and progress\n",
    "    proc = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1,\n",
    "        env={**os.environ, \"TMPDIR\": \"/tmp\", \"TEMP\": \"/tmp\", \"TMP\": \"/tmp\"}\n",
    "    )\n",
    "    \n",
    "    print(\"Progress:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    last_progress_time = time.time()\n",
    "    for line in proc.stdout:\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        # Update stage based on output\n",
    "        for marker, stage_name in stage_markers.items():\n",
    "            if marker in line:\n",
    "                if \"Finished Jackhmmer\" in line:\n",
    "                    jackhmmer_count += 1\n",
    "                    current_stage = f\"Jackhmmer ({jackhmmer_count}/{jackhmmer_total})\"\n",
    "                else:\n",
    "                    current_stage = stage_name\n",
    "        \n",
    "        # Print progress update every 2 seconds or on stage change\n",
    "        if time.time() - last_progress_time >= 2:\n",
    "            print_progress(current_stage, elapsed)\n",
    "            last_progress_time = time.time()\n",
    "        \n",
    "        # Also print important log lines\n",
    "        if any(x in line for x in [\"[+]\", \"[X]\", \"Error\", \"error\", \"Finished\", \"Running fold job\", \"Output will be written\"]):\n",
    "            print()  # newline before log\n",
    "            print(line.rstrip())\n",
    "    \n",
    "    rc = proc.wait()\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print()  # Final newline\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Total time: {format_elapsed(elapsed)}\")\n",
    "    if rc == 0:\n",
    "        print(\"[+] AF3 test prediction completed successfully!\")\n",
    "    else:\n",
    "        print(f\"[X] AF3 test prediction failed with code {rc}\")\n",
    "        # Cleanup any remaining temp files\n",
    "        print(\"\\nCleaning up temp files...\")\n",
    "        for tmp_dir in TMPDIR.glob(\"tmp*\"):\n",
    "            try:\n",
    "                shutil.rmtree(tmp_dir, ignore_errors=True)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "check-outputs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking outputs in: /cwork/hsb26/ab_seq_bind_analysis/data/processed/af3_outputs/test_run\n",
      "============================================================\n",
      "Found 29 files/directories:\n",
      "\n",
      "  test_minimal/\n",
      "  test_minimal/.ipynb_checkpoints/\n",
      "  test_minimal/.ipynb_checkpoints/test_minimal_data-checkpoint.json (1,017,017 bytes)\n",
      "  test_minimal/TERMS_OF_USE.md (13,036 bytes)\n",
      "  test_minimal/seed-1_sample-0/\n",
      "  test_minimal/seed-1_sample-0/test_minimal_seed-1_sample-0_confidences.json (32,050 bytes)\n",
      "  test_minimal/seed-1_sample-0/test_minimal_seed-1_sample-0_model.cif (43,486 bytes)\n",
      "  test_minimal/seed-1_sample-0/test_minimal_seed-1_sample-0_summary_confidences.json (246 bytes)\n",
      "  test_minimal/seed-1_sample-1/\n",
      "  test_minimal/seed-1_sample-1/test_minimal_seed-1_sample-1_confidences.json (32,043 bytes)\n",
      "  test_minimal/seed-1_sample-1/test_minimal_seed-1_sample-1_model.cif (43,486 bytes)\n",
      "  test_minimal/seed-1_sample-1/test_minimal_seed-1_sample-1_summary_confidences.json (246 bytes)\n",
      "  test_minimal/seed-1_sample-2/\n",
      "  test_minimal/seed-1_sample-2/test_minimal_seed-1_sample-2_confidences.json (32,053 bytes)\n",
      "  test_minimal/seed-1_sample-2/test_minimal_seed-1_sample-2_model.cif (43,486 bytes)\n",
      "  test_minimal/seed-1_sample-2/test_minimal_seed-1_sample-2_summary_confidences.json (246 bytes)\n",
      "  test_minimal/seed-1_sample-3/\n",
      "  test_minimal/seed-1_sample-3/test_minimal_seed-1_sample-3_confidences.json (32,013 bytes)\n",
      "  test_minimal/seed-1_sample-3/test_minimal_seed-1_sample-3_model.cif (43,040 bytes)\n",
      "  test_minimal/seed-1_sample-3/test_minimal_seed-1_sample-3_summary_confidences.json (246 bytes)\n",
      "  ... and 9 more\n"
     ]
    }
   ],
   "source": [
    "# Check what outputs were generated\n",
    "print(f\"Checking outputs in: {TEST_OUTPUT_DIR}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if TEST_OUTPUT_DIR.exists():\n",
    "    files = list(TEST_OUTPUT_DIR.rglob(\"*\"))\n",
    "    if files:\n",
    "        print(f\"Found {len(files)} files/directories:\\n\")\n",
    "        for f in sorted(files)[:20]:\n",
    "            rel = f.relative_to(TEST_OUTPUT_DIR)\n",
    "            if f.is_file():\n",
    "                size = f.stat().st_size\n",
    "                print(f\"  {rel} ({size:,} bytes)\")\n",
    "            else:\n",
    "                print(f\"  {rel}/\")\n",
    "        if len(files) > 20:\n",
    "            print(f\"  ... and {len(files) - 20} more\")\n",
    "    else:\n",
    "        print(\"No output files found (prediction may not have run yet).\")\n",
    "else:\n",
    "    print(\"Output directory does not exist yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "If all tests pass:\n",
    "- Environment is correctly configured\n",
    "- Container loads and GPU is accessible\n",
    "- AF3 modules can be imported\n",
    "- (Optional) Full prediction pipeline works\n",
    "\n",
    "You're ready to run predictions using `03_run_af3_prediction.ipynb`!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "af3",
   "language": "python",
   "name": "af3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
